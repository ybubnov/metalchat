# MetalChat - Llama inference for Apple Silicon

MetalChat is a [Metal](https://developer.apple.com/metal/)-accelerated C++ framework and command
line interpreter for inference of [Meta Llama](https://www.llama.com/) models.

> [!IMPORTANT]
> The library API and CLI are under active development, therefore they may change without any
> deprecation notice. See issues tab for the list of known issues or missing features.

## Installation

The framework and binary could be installed using Homebrew package manager in a following way
```sh
brew tap ybubnov/metalchat https://github.com/ybubnov/metalchat
brew install --HEAD metalchat
```

## License

The MetalChat is distributed under GPLv3 license. See the [LICENSE](LICENSE) file for full license
text.
