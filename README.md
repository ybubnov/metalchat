# MetalChat - Llama inference for Apple Silicon

MetalChat is a [Metal](https://developer.apple.com/metal/)-accelerated C++ framework and command
line interpreter for inference of [Meta Llama](https://www.llama.com/) models.

## License

The MetalChat is distributed under GPLv3 license. See the [LICENSE](LICENSE) file for full license
text.
